{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Review Collector\n",
    "\n",
    "Simple functions for collecting reviews for games via Steam Web API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API description\n",
    "\n",
    "Maximum of 100k requests per day. (https://steamcommunity.com/dev/apiterms)\n",
    "\n",
    "Review API:\n",
    "https://partner.steamgames.com/doc/store/getreviews\n",
    "\n",
    "## Response:\n",
    "- success - 1 if the query was successful\n",
    "- query_summary - Returned in the first request\n",
    "    - num_reviews - The number of reviews returned in this response\n",
    "    - review_score - The review score\n",
    "    - review_score_desc - The description of the review score\n",
    "    - total_positive - Total number of positive reviews\n",
    "    - total_negative - Total number of negative reviews\n",
    "    - total_reviews - Total number of reviews matching the query parameters\n",
    "- cursor - The value to pass into the next request as the cursor to retrieve the next batch of reviews\n",
    "\n",
    "### Reviews\n",
    "- recommendationid - The unique id of the recommendation\n",
    "- author\n",
    "    - steamid - the userâ€™s SteamID\n",
    "    - num_games_owned - number of games owned by the user\n",
    "    - num_reviews - number of reviews written by the user\n",
    "    - playtime_forever - lifetime playtime tracked in this app\n",
    "    - playtime_last_two_weeks - playtime tracked in the past two weeks for this app\n",
    "    - playtime_at_review - playtime when the review was written\n",
    "    - last_played - time for when the user last played\n",
    "- language - language the user indicated when authoring the review\n",
    "- review - text of written review\n",
    "- timestamp_created - date the review was created (unix timestamp)\n",
    "- timestamp_updated - date the review was last updated (unix timestamp)\n",
    "- voted_up - true means it was a positive recommendation\n",
    "- votes_up - the number of users that found this review helpful\n",
    "- votes_funny - the number of users that found this review funny\n",
    "- weighted_vote_score - helpfulness score\n",
    "- comment_count - number of comments posted on this review\n",
    "- steam_purchase - true if the user purchased the game on Steam\n",
    "- received_for_free - true if the user checked a box saying they got the app for free\n",
    "- written_during_early_access - true if the user posted this review while the game was in Early Access\n",
    "- developer_response - text of the developer response, if any\n",
    "- timestamp_dev_responded - Unix timestamp of when the developer responded, if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single request\n",
    "r_string = 'https://store.steampowered.com/appreviews/424370?json=1&num_per_page=1&filter=recent&language=english&cursor=*'\n",
    "r = requests.get(r_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking status code\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_steam_reviews(app_id, filt='recent', num_per_page=100, language='english', cursor='*', meta=False):\n",
    "    \"\"\"Uses Steam Web API to fetch reviews from a specified game.\n",
    "\n",
    "    Implemented according to Steam Web API specification for fetching game reviews. \n",
    "    https://partner.steamgames.com/doc/store/getreviews\n",
    "\n",
    "    Args:\n",
    "        app_id: Steam id of the game, found via Steam Store Page of a game.\n",
    "        filt: Optional;  How the reviews are ordered.\n",
    "        num_per_page: Optional;  The number of results to return for each query, 100 is maximum.\n",
    "        language: Optional;  Language filter for the reviews.\n",
    "        cursor: Optional;  The cursor used to fetch the next set of reviews according to API specification.\n",
    "        meta: Optional;  Used to return additional meta information, a summary of the reviews of the game.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with metadata, reviews and next cursor.\n",
    "\n",
    "    Raises:\n",
    "        raise_for_status if return code is not 200.\n",
    "    \"\"\"\n",
    "    \n",
    "    r_string = f'https://store.steampowered.com/appreviews/{app_id}?json=1&num_per_page={num_per_page}&filter={filt}&language={language}&cursor={cursor}'\n",
    "    r = requests.get(r_string)\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        payload = r.json()\n",
    "        \n",
    "        if not payload['success'] == 1:\n",
    "            print('Something was wrong with retrieving the payload.')\n",
    "            \n",
    "        # Save meta data.\n",
    "        if meta:\n",
    "            metadata = payload['query_summary']\n",
    "        else:\n",
    "            metadata = None\n",
    "            \n",
    "        # Remove recommendation id and author steam id for some sanitation.\n",
    "        review_list = []\n",
    "        for review in payload['reviews']:\n",
    "            # Move information about author\n",
    "            review['num_games_owned'] = review['author']['num_games_owned']\n",
    "            review['num_reviews'] = review['author']['num_reviews']\n",
    "            \n",
    "            if 'playtime_forever' in review['author']:\n",
    "                review['playtime_forever'] = review['author']['playtime_forever']\n",
    "            else:\n",
    "                review['playtime_forever'] = 0\n",
    "                \n",
    "            if 'playtime_last_two_weeks' in review['author']:\n",
    "                review['playtime_last_two_weeks'] = review['author']['playtime_last_two_weeks']\n",
    "            else:\n",
    "                review['playtime_last_two_weeks'] = 0\n",
    "                \n",
    "            if 'playtime_at_review' in review['author']:\n",
    "                review['playtime_at_review'] = review['author']['playtime_at_review']\n",
    "            else:\n",
    "                review['playtime_at_review'] = 0\n",
    "                \n",
    "            if 'last_played' in review['author']:\n",
    "                review['last_played'] = review['author']['last_played']\n",
    "            else:\n",
    "                review['last_played'] = np.nan\n",
    "                \n",
    "            \n",
    "            # Remove identifiable information\n",
    "            del review['recommendationid']\n",
    "            del review['author']\n",
    "            \n",
    "            # Remove developer response and response date if existing.\n",
    "            if 'developer_response' in review:\n",
    "                del review['developer_response']\n",
    "                \n",
    "            if 'timestamp_dev_responded' in review:\n",
    "                del review['timestamp_dev_responded']\n",
    "            \n",
    "            # Save each review in a new structure.\n",
    "            review_list.append(review)\n",
    "            \n",
    "            \n",
    "        # Fetch cursor for next dataset\n",
    "        rec_cursor = payload['cursor']\n",
    "        \n",
    "        return {'meta': metadata, 'reviews':review_list, 'cursor':rec_cursor}\n",
    "    \n",
    "    else:\n",
    "        # Error handling\n",
    "        r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for meta data\n",
    "res = fetch_steam_reviews('424370', num_per_page=0, cursor='*', meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_n_reviews(app_id, n_calls, output_folder, init_cursor=False, **kwargs):\n",
    "    \"\"\"Process a maximum number of API calls and stores the output.\n",
    "\n",
    "    Using fetch_steam_reviews function to run a number of queries, at maximum n_calls many, to fetch a larger dataset.\n",
    "    This is used to safetly query the API without overusing the API according to https://steamcommunity.com/dev/apiterms.\n",
    "    The data is stored using parquet file format.\n",
    "\n",
    "    Args:\n",
    "        app_id: Steam id of the game, found via Steam Store Page of a game.\n",
    "        n_calls: Maximum number of queries to the API.\n",
    "        output_folder: Folder where parquet files are stored.\n",
    "        init_cursor: Optional;  The cursor used to query first.\n",
    "        **kwargs: Optional;  For future use.\n",
    "\n",
    "    Returns:\n",
    "        N/A\n",
    "\n",
    "    Raises:\n",
    "        IOError if output folder is not found.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check output folder.\n",
    "    if not os.path.exists(output_folder):\n",
    "        raise IOError(f\"Specified output path does not exist! {output_folder}\")\n",
    "        \n",
    "        \n",
    "    # Check content of output folder, if there is previous mining done for this app. Not checking for duplicate information!\n",
    "    outdir_content = os.listdir(output_folder)\n",
    "    if any(f'review_{app_id}' in f for f in outdir_content):\n",
    "        # There exist some matches, set the suffix number to be next unique number.\n",
    "        suffix = sum(f'review_{app_id}' in f for f in outdir_content) + 1\n",
    "    else:\n",
    "        suffix = 1\n",
    "        \n",
    "    \n",
    "    # Check if metadata file exits, create file otherwise.\n",
    "    metafile = f'metadata_{app_id}.txt'\n",
    "    meta_fullpath = os.path.join(output_folder, metafile)\n",
    "    if not os.path.isfile(meta_fullpath):\n",
    "        with open(meta_fullpath, 'w') as metafile:\n",
    "            metafile.write('Timestamp\\tIteration\\tCurrent Cursor\\tNext Cursor\\tFilename\\n')\n",
    "            \n",
    "    \n",
    "    # Initialized to * for the first fetch as specified in the API documents.\n",
    "    if not init_cursor:\n",
    "        next_cursor = '*'\n",
    "    else:\n",
    "        next_cursor = init_cursor\n",
    "    \n",
    "    # Iterate using the cursor from previous query\n",
    "    for n in range(n_calls):\n",
    "        res = fetch_steam_reviews(app_id, cursor=next_cursor, meta=False, filt='recent', num_per_page=100, language='english', )\n",
    "        \n",
    "        # Stop if there is no new cursor, then there is no more data to collect\n",
    "        if next_cursor == urllib.parse.quote_plus(res['cursor']):\n",
    "            print(\"No more data to fetch, closing!\")\n",
    "            break\n",
    "        \n",
    "        # Create df, convert columns and add metadata for cursor\n",
    "        df = pd.DataFrame.from_dict(res['reviews'])\n",
    "        \n",
    "        df['last_played'] = pd.to_datetime(df['last_played'], unit='s', errors='coerce')\n",
    "        df['timestamp_created'] = pd.to_datetime(df['timestamp_created'], unit='s')\n",
    "        df['timestamp_updated'] = pd.to_datetime(df['timestamp_updated'], unit='s')\n",
    "        \n",
    "        # Cast dtypes\n",
    "        df = df.convert_dtypes()\n",
    "        df['weighted_vote_score'] = df['weighted_vote_score'].astype('float32') # This will change the value, but not significantly.\n",
    "        \n",
    "        # Write to disk\n",
    "        filename = f'review_{app_id}_{suffix}.parquet'\n",
    "        path = os.path.join(output_folder, filename)\n",
    "        df.to_parquet(path)\n",
    "        \n",
    "        # Update metadata file\n",
    "        with open(meta_fullpath, 'a') as metafile:\n",
    "            metafile.write(f\"{datetime.now()}\\t{n}\\t{next_cursor}\\t{urllib.parse.quote_plus(res['cursor'])}\\t{filename}\\n\")\n",
    "        \n",
    "        # Step variables\n",
    "        next_cursor = urllib.parse.quote_plus(res['cursor'])\n",
    "        suffix = suffix + 1\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more data to fetch, closing!\n"
     ]
    }
   ],
   "source": [
    "process_n_reviews('424370', 700, 'D:\\\\data\\\\validation', init_cursor='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for reading parquet file to pandas dataframe\n",
    "dg = pd.read_parquet('D:\\\\data\\\\validation\\\\review_424370_5.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(input_folder):\n",
    "    \"\"\"Merging all parquet files in a folder.\n",
    "\n",
    "    After multiple data files are saved in a folder it can be merged to a single file for easier handling upon analysis.\n",
    "\n",
    "    Args:\n",
    "        input_folder: Folder where parquet files are stored.\n",
    "\n",
    "    Returns:\n",
    "        N/A\n",
    "\n",
    "    Raises:\n",
    "        IOError if input folder is not found.\n",
    "        IOError if no data is imported with the specified input folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check input folder.\n",
    "    if not os.path.exists(input_folder):\n",
    "        raise IOError(f\"Specified input path does not exist! {input_folder}\")\n",
    "        \n",
    "    df_out = pd.DataFrame()   \n",
    "\n",
    "    # Iterate over all data files appending content to a larger dataframe\n",
    "    for file in os.listdir(input_folder):\n",
    "        if not file.endswith(\".parquet\"):\n",
    "            continue\n",
    "            \n",
    "        df_tmp = pd.read_parquet(os.path.join(input_folder, file))\n",
    "        \n",
    "        if df_out.empty:\n",
    "            df_out = df_tmp\n",
    "        else:\n",
    "            df_out = df_out.append(df_tmp, ignore_index=True)\n",
    "    \n",
    "    # Save data if df_out is not empty\n",
    "    if not df_out.empty:\n",
    "        filename = f'review_merged.parquet'\n",
    "        path = os.path.join(input_folder, filename)\n",
    "        df_out.to_parquet(path)\n",
    "    else:\n",
    "        raise IOError('Error, the dataframe was empty!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of merging data\n",
    "merge_data('D:\\\\data\\\\test_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data extraction: GTA V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more data to fetch, closing!\n"
     ]
    }
   ],
   "source": [
    "process_n_reviews('271590', 3000, 'D:\\\\data\\\\test_train', init_cursor='*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
