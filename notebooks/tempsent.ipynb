{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Sentiment Data Timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook consists of code for performing sentiment analysis on game reviews from Steam.\n",
    "\n",
    "A summary of the content exists below and a table of contents as well. In another notebook is code for using Steam API for mining the reviews. Data is not provided due to API Terms of Use (https://steamcommunity.com/dev/apiterms). Details on choices made are stated in the report.\n",
    "\n",
    "This is intended to be finalized in a python package at a later stage.\n",
    "\n",
    "\n",
    "### Plan\n",
    "- Data import and processing e.g. balancing dataset\n",
    "- Model evaluation (GTA V reviews)\n",
    "- Majority voting\n",
    "- Model selection and final training\n",
    "- Model validation (Wolcen reviews)\n",
    "- Visualization of the predictions over the time axis\n",
    "\n",
    "### Algorithms\n",
    "- Baseline classifier (dummy classifier)\n",
    "- Multinomial Naive Bayes\n",
    "- SVM (Linear)\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- Random Subspaces (SVM)\n",
    "\n",
    "### Preprocessing\n",
    "- Unigrams with Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "0. Imports\n",
    "1. Data Ingestion\n",
    "2. Helper Functions\n",
    "3. Model Evaluation \n",
    "    1. Dummy Classifier\n",
    "    2. Multinomial Naive Bayes\n",
    "    3. SGD - Linear SVM\n",
    "    4. Logistic Regression\n",
    "    5. KNN\n",
    "    6. Random Subspaces (SVM)\n",
    "4. Majority Voting\n",
    "5. Validation of Final Model\n",
    "6. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Helpers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Visualization\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, output_file, save\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Panel\n",
    "from bokeh.models.widgets import Tabs\n",
    "from bokeh.models import DatetimeTickFormatter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 274865 entries, 0 to 274864\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   language                     274865 non-null  string        \n",
      " 1   review                       274865 non-null  string        \n",
      " 2   timestamp_created            274865 non-null  datetime64[ns]\n",
      " 3   timestamp_updated            274865 non-null  datetime64[ns]\n",
      " 4   voted_up                     274865 non-null  boolean       \n",
      " 5   votes_up                     274865 non-null  Int64         \n",
      " 6   votes_funny                  274865 non-null  Int64         \n",
      " 7   weighted_vote_score          274865 non-null  float32       \n",
      " 8   comment_count                274865 non-null  Int64         \n",
      " 9   steam_purchase               274865 non-null  boolean       \n",
      " 10  received_for_free            274865 non-null  boolean       \n",
      " 11  written_during_early_access  274865 non-null  boolean       \n",
      " 12  num_games_owned              274865 non-null  Int64         \n",
      " 13  num_reviews                  274865 non-null  Int64         \n",
      " 14  playtime_forever             274865 non-null  Int64         \n",
      " 15  playtime_last_two_weeks      274865 non-null  Int64         \n",
      " 16  playtime_at_review           274865 non-null  Int64         \n",
      " 17  last_played                  274865 non-null  datetime64[ns]\n",
      "dtypes: Int64(8), boolean(4), datetime64[ns](3), float32(1), string(2)\n",
      "memory usage: 32.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_parquet('D:\\\\data\\\\test_train\\\\review_merged.parquet')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    205874\n",
       "0     68991\n",
       "Name: voted_up, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from boolean to int and check dataset balance\n",
    "df['voted_up'] = df['voted_up'].astype('int64')\n",
    "df['voted_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance Dataset\n",
    "# Divide dataframe into positive and negative\n",
    "df_pos = df[df['voted_up'] == 0]\n",
    "df_neg = df[df['voted_up'] == 1]\n",
    "\n",
    "# Under-sample larger dataframe\n",
    "if len(df_pos.index) == len(df_neg.index):\n",
    "    # Dataset is balanced\n",
    "    pass\n",
    "elif len(df_pos.index) > len(df_neg.index):\n",
    "    # Positive has higher count, under-sample positive and then merge again\n",
    "    df_pos = df_pos.sample(len(df_neg.index))\n",
    "    df = pd.concat([df_pos, df_neg], axis=0)\n",
    "else:\n",
    "    # Negative has higher count, under-sample negative and then merge again\n",
    "    df_neg = df_neg.sample(len(df_pos.index))\n",
    "    df = pd.concat([df_pos, df_neg], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    68991\n",
       "0    68991\n",
       "Name: voted_up, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that data is now balanced\n",
    "df['voted_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['voted_up'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count vector from train data, using TF if binary=False and TP if binary=True\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=False)\n",
    "X = vectorizer.fit_transform(X_train)\n",
    "Y = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_predicted):\n",
    "    \"\"\"Prints evaluation metrics from the predicted classification.\n",
    "\n",
    "    Using Scikit-learn functions with y_true and y_predicted to calculate metrics. \n",
    "    These are then printed into an easily read format.\n",
    "\n",
    "    Args:\n",
    "        y_true: The true y labels.\n",
    "        y_predicted: The predicted y labels\n",
    "\n",
    "    Returns:\n",
    "        N/A\n",
    "\n",
    "    Raises:\n",
    "        N/A\n",
    "    \"\"\"\n",
    "        \n",
    "    conf_mat = confusion_matrix(y_true, y_predicted)\n",
    "    \n",
    "    print(\"======== CONFUSION MATRIX ========\")\n",
    "    print(\"\\t0\\t1\")\n",
    "    print(f\"0\\t{conf_mat[0][0]}\\t{conf_mat[0][1]}\")\n",
    "    print(f\"1\\t{conf_mat[1][0]}\\t{conf_mat[1][1]}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"======== CLASSIFICATION REPORT ========\")\n",
    "    print(classification_report(y_true, y_predicted))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. Dummy Classifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "# Train\n",
    "dummy_clf.fit(X, y_train)\n",
    "\n",
    "# Predict\n",
    "y_dummy_train = dummy_clf.predict(X)\n",
    "y_dummy_test = dummy_clf.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t24015\t24172\n",
      "1\t24179\t24221\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50     48187\n",
      "           1       0.50      0.50      0.50     48400\n",
      "\n",
      "    accuracy                           0.50     96587\n",
      "   macro avg       0.50      0.50      0.50     96587\n",
      "weighted avg       0.50      0.50      0.50     96587\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_dummy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t10480\t10324\n",
      "1\t10276\t10315\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50     20804\n",
      "           1       0.50      0.50      0.50     20591\n",
      "\n",
      "    accuracy                           0.50     41395\n",
      "   macro avg       0.50      0.50      0.50     41395\n",
      "weighted avg       0.50      0.50      0.50     41395\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_dummy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Multinomial Naive Bayes\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_train = clf.predict(X)\n",
    "y_pred_test = clf.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t41980\t6207\n",
      "1\t5356\t43044\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     48187\n",
      "           1       0.87      0.89      0.88     48400\n",
      "\n",
      "    accuracy                           0.88     96587\n",
      "   macro avg       0.88      0.88      0.88     96587\n",
      "weighted avg       0.88      0.88      0.88     96587\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t18042\t2762\n",
      "1\t2841\t17750\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87     20804\n",
      "           1       0.87      0.86      0.86     20591\n",
      "\n",
      "    accuracy                           0.86     41395\n",
      "   macro avg       0.86      0.86      0.86     41395\n",
      "weighted avg       0.86      0.86      0.86     41395\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C. SGD - Linear SVM\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(tol=0.0001)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "clf_sgd = SGDClassifier(max_iter=1000, tol=1e-4)\n",
    "clf_sgd.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_train_sgd = clf_sgd.predict(X)\n",
    "y_pred_test_sgd = clf_sgd.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t40443\t7744\n",
      "1\t3350\t45050\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88     48187\n",
      "           1       0.85      0.93      0.89     48400\n",
      "\n",
      "    accuracy                           0.89     96587\n",
      "   macro avg       0.89      0.89      0.88     96587\n",
      "weighted avg       0.89      0.89      0.88     96587\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_pred_train_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t16851\t3953\n",
      "1\t1794\t18797\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85     20804\n",
      "           1       0.83      0.91      0.87     20591\n",
      "\n",
      "    accuracy                           0.86     41395\n",
      "   macro avg       0.87      0.86      0.86     41395\n",
      "weighted avg       0.87      0.86      0.86     41395\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred_test_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D. Logistic Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "clf_lr = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "clf_lr.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_train_lr = clf_lr.predict(X)\n",
    "y_pred_test_lr = clf_lr.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t42155\t6032\n",
      "1\t3049\t45351\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90     48187\n",
      "           1       0.88      0.94      0.91     48400\n",
      "\n",
      "    accuracy                           0.91     96587\n",
      "   macro avg       0.91      0.91      0.91     96587\n",
      "weighted avg       0.91      0.91      0.91     96587\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_pred_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t17084\t3720\n",
      "1\t2015\t18576\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.86     20804\n",
      "           1       0.83      0.90      0.87     20591\n",
      "\n",
      "    accuracy                           0.86     41395\n",
      "   macro avg       0.86      0.86      0.86     41395\n",
      "weighted avg       0.86      0.86      0.86     41395\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3E. KNN\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_train_knn = clf_knn.predict(X)\n",
    "y_pred_test_knn = clf_knn.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t34689\t13498\n",
      "1\t2900\t45500\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81     48187\n",
      "           1       0.77      0.94      0.85     48400\n",
      "\n",
      "    accuracy                           0.83     96587\n",
      "   macro avg       0.85      0.83      0.83     96587\n",
      "weighted avg       0.85      0.83      0.83     96587\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_pred_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t13461\t7343\n",
      "1\t1709\t18882\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.65      0.75     20804\n",
      "           1       0.72      0.92      0.81     20591\n",
      "\n",
      "    accuracy                           0.78     41395\n",
      "   macro avg       0.80      0.78      0.78     41395\n",
      "weighted avg       0.80      0.78      0.78     41395\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3F. Random Subspaces (SVM)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "\n",
    "Very complex for large feature and large samples O(n_features * n_samles^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(), bootstrap_features=True, n_estimators=2,\n",
       "                  n_jobs=4, random_state=422)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "clf_rs = BaggingClassifier(base_estimator=SVC(), n_estimators=2, random_state=422, bootstrap_features=True, n_jobs=4)\n",
    "clf_rs.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_train_3 = clf_rs.predict(X)\n",
    "y_pred_test_3 = clf_rs.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t38322\t9865\n",
      "1\t6028\t42372\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83     48187\n",
      "           1       0.81      0.88      0.84     48400\n",
      "\n",
      "    accuracy                           0.84     96587\n",
      "   macro avg       0.84      0.84      0.84     96587\n",
      "weighted avg       0.84      0.84      0.84     96587\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_pred_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t16446\t4358\n",
      "1\t3005\t17586\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82     20804\n",
      "           1       0.80      0.85      0.83     20591\n",
      "\n",
      "    accuracy                           0.82     41395\n",
      "   macro avg       0.82      0.82      0.82     41395\n",
      "weighted avg       0.82      0.82      0.82     41395\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultNB, Linear SVM, KNN\n",
    "voting_test = y_pred_test + y_pred_test_sgd + y_pred_test_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_test[voting_test <= 1] = 0\n",
    "voting_test[voting_test >= 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t17210\t3594\n",
      "1\t1891\t18700\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86     20804\n",
      "           1       0.84      0.91      0.87     20591\n",
      "\n",
      "    accuracy                           0.87     41395\n",
      "   macro avg       0.87      0.87      0.87     41395\n",
      "weighted avg       0.87      0.87      0.87     41395\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, voting_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation of Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = pd.read_parquet('D:\\\\data\\\\validation\\\\review_merged.parquet')\n",
    "dv['voted_up'] = dv['voted_up'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use complete training corpus for training validation model\n",
    "vectorizer_val = CountVectorizer(stop_words='english', binary=False)\n",
    "X_train_val = vectorizer_val.fit_transform(df['review'])\n",
    "y_train_val = df['voted_up']\n",
    "\n",
    "clf_NB_val = MultinomialNB()\n",
    "clf_NB_val.fit(X_train_val, y_train_val)\n",
    "\n",
    "clf_sgd_val = SGDClassifier(max_iter=1000, tol=1e-4)\n",
    "clf_sgd_val.fit(X_train_val, y_train_val)\n",
    "\n",
    "clf_lr_val = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "clf_lr_val.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = vectorizer_val.transform(dv['review'])\n",
    "NB_eval = clf_NB_val.predict(V)\n",
    "SVM_eval = clf_sgd_val.predict(V)\n",
    "LR_eval = clf_lr_val.predict(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t8839\t1828\n",
      "1\t2945\t10721\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79     10667\n",
      "           1       0.85      0.78      0.82     13666\n",
      "\n",
      "    accuracy                           0.80     24333\n",
      "   macro avg       0.80      0.81      0.80     24333\n",
      "weighted avg       0.81      0.80      0.80     24333\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(dv['voted_up'], NB_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t8137\t2530\n",
      "1\t1746\t11920\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79     10667\n",
      "           1       0.82      0.87      0.85     13666\n",
      "\n",
      "    accuracy                           0.82     24333\n",
      "   macro avg       0.82      0.82      0.82     24333\n",
      "weighted avg       0.82      0.82      0.82     24333\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(dv['voted_up'], SVM_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t8342\t2325\n",
      "1\t2092\t11574\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79     10667\n",
      "           1       0.83      0.85      0.84     13666\n",
      "\n",
      "    accuracy                           0.82     24333\n",
      "   macro avg       0.82      0.81      0.82     24333\n",
      "weighted avg       0.82      0.82      0.82     24333\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(dv['voted_up'], LR_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t0\t1\n",
      "0\t8420\t2247\n",
      "1\t1914\t11752\n",
      "\n",
      "\n",
      "======== CLASSIFICATION REPORT ========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80     10667\n",
      "           1       0.84      0.86      0.85     13666\n",
      "\n",
      "    accuracy                           0.83     24333\n",
      "   macro avg       0.83      0.82      0.83     24333\n",
      "weighted avg       0.83      0.83      0.83     24333\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "majority_vote = NB_eval + SVM_eval + LR_eval\n",
    "majority_vote[majority_vote <= 1] = 0\n",
    "majority_vote[majority_vote >= 2] = 1\n",
    "evaluate(dv['voted_up'], majority_vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "Inspiration: https://towardsdatascience.com/interactive-histograms-with-bokeh-202b522265f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = dv\n",
    "df_viz['predicted'] = majority_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24333 entries, 0 to 24332\n",
      "Data columns (total 19 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   language                     24333 non-null  string        \n",
      " 1   review                       24333 non-null  string        \n",
      " 2   timestamp_created            24333 non-null  datetime64[ns]\n",
      " 3   timestamp_updated            24333 non-null  datetime64[ns]\n",
      " 4   voted_up                     24333 non-null  int64         \n",
      " 5   votes_up                     24333 non-null  Int64         \n",
      " 6   votes_funny                  24333 non-null  Int64         \n",
      " 7   weighted_vote_score          24333 non-null  float32       \n",
      " 8   comment_count                24333 non-null  Int64         \n",
      " 9   steam_purchase               24333 non-null  boolean       \n",
      " 10  received_for_free            24333 non-null  boolean       \n",
      " 11  written_during_early_access  24333 non-null  boolean       \n",
      " 12  num_games_owned              24333 non-null  Int64         \n",
      " 13  num_reviews                  24333 non-null  Int64         \n",
      " 14  playtime_forever             24333 non-null  Int64         \n",
      " 15  playtime_last_two_weeks      24333 non-null  Int64         \n",
      " 16  playtime_at_review           24333 non-null  Int64         \n",
      " 17  last_played                  24333 non-null  datetime64[ns]\n",
      " 18  predicted                    24333 non-null  int64         \n",
      "dtypes: Int64(8), boolean(3), datetime64[ns](3), float32(1), int64(2), string(2)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_viz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_pos = df_viz[df_viz[\"predicted\"] == 1]\n",
    "df_viz_neg = df_viz[df_viz[\"predicted\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reviews(df_pos, df_neg, x_label, vectorizer, log_scale=False, save_name=None):\n",
    "    \"\"\"Creates a figure with positive and negative reviews as two histograms, where negative reviews are inverted along y-axis.\n",
    "\n",
    "    Utilizing Bokeh and Numpy to calculate histograms for both positive and negative reviews. Then \n",
    "    these are plotted and essential tools like tool tips and hover tools are added.\n",
    "\n",
    "    Args:\n",
    "        df_pos: Dataframe of positive reviews.\n",
    "        df_neg: Dataframe of negative reviews.\n",
    "        x_label: The x label that has the timestamp for each review.\n",
    "        log_scale: Optional; If the count is very uneven the log scale can be used by setting log_scale=True.\n",
    "        save: Optional; Set to output name if the figure should be saved to html instead of shown, e.g. save='plot_7'\n",
    "\n",
    "    Returns:\n",
    "        N/A\n",
    "\n",
    "    Raises:\n",
    "        N/A\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define Colors\n",
    "    # Positive, negative, hover, background\n",
    "    colors=[\"#99B898\", \"#FF847C\", \"#FECEA8\", \"#2A363B\"]\n",
    "\n",
    "    # Helper function for handling the datetime to string convertion\n",
    "    def fix_time(time):\n",
    "        \"\"\"Converts datetime object to formatted string.\n",
    "\n",
    "        From Pandas datetime object converted using datetime package into a string.\n",
    "\n",
    "        Args:\n",
    "            time: Vector of pandas datetime values.\n",
    "\n",
    "        Returns:\n",
    "            Converted string.\n",
    "\n",
    "        Raises:\n",
    "            N/A\n",
    "        \"\"\"\n",
    "        return datetime.fromtimestamp(time // 1000).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Use Numpy to calculate histogram and saving to column data store\n",
    "    def create_columndatastore(df, x_label, sentiment, log_scale):\n",
    "        \"\"\"Creates the ColumnDataStore for Bokeh from histogram.\n",
    "\n",
    "        The histogram is calculated using Numpy and then the data is prepared for plotting before creating \n",
    "        the ColumnDataStore object.\n",
    "\n",
    "        Args:\n",
    "            df: Dataframe with datetime data.\n",
    "            x_label: The label for the datetime data.\n",
    "            sentiment: Controls if the histogram is inverted or not. 'neg' inverts the y-axis and 'pos' uses it as is.\n",
    "            log_scale: If y-axis is scaled by log or not.\n",
    "\n",
    "        Returns:\n",
    "            ColumnDataStore object.\n",
    "\n",
    "        Raises:\n",
    "            N/A\n",
    "        \"\"\"\n",
    "            \n",
    "        hist, edges = np.histogram(df[x_label].astype(np.int64) // 10**6, bins = 100)\n",
    "        \n",
    "        hist_df = pd.DataFrame({x_label: hist,\n",
    "                                 \"left\": edges[:-1],\n",
    "                                 \"right\": edges[1:]})\n",
    "        hist_df[\"interval\"] = [f\"{fix_time(left)} to {fix_time(right)}\" for left, \n",
    "                               right in zip(hist_df[\"left\"], hist_df[\"right\"])]\n",
    "        \n",
    "        # Calculate 5 most common words for each interval to use with tool tip later\n",
    "        n = 5\n",
    "        most_common = []\n",
    "        for row in hist_df.itertuples():\n",
    "            # Select all samples within the datetime span\n",
    "            df_selection = df[(df[x_label].astype(np.int64) // 10**6 >= row.left) & \n",
    "                              (df[x_label].astype(np.int64) // 10**6 <= row.right)]\n",
    "            \n",
    "            # Transform and get frequency\n",
    "            tmp_vector = vectorizer.transform(df_selection['review'].tolist())\n",
    "            freqs = zip(vectorizer.get_feature_names(), tmp_vector.sum(axis=0).tolist()[0])  \n",
    "            \n",
    "            # Sort, format and save\n",
    "            top_n = sorted(freqs, key=lambda x: -x[1])[:n]\n",
    "            formatted = ''.join([f\"{a}: {b}<br>\" for a,b in top_n])\n",
    "            most_common.append(formatted)\n",
    "        \n",
    "        # Add to hist_df\n",
    "        hist_df['top_n'] = most_common\n",
    "        \n",
    "        if log_scale:\n",
    "            with np.errstate(divide='ignore'):\n",
    "                hist_df[x_label] = np.nan_to_num(np.log10(hist_df[x_label]), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            \n",
    "        # If negative reviews flip the axis\n",
    "        if sentiment == 'neg':\n",
    "            hist_df[x_label] = -hist_df[x_label]\n",
    "        \n",
    "        return ColumnDataSource(hist_df)\n",
    "\n",
    "    src_pos = create_columndatastore(df_pos, x_label, 'pos', log_scale)\n",
    "    src_neg = create_columndatastore(df_neg, x_label, 'neg', log_scale)\n",
    "    \n",
    "    # Change tool tips strings if log scale is used.\n",
    "    if log_scale:\n",
    "        y_axis = \"Log base 10\"\n",
    "    else:\n",
    "        y_axis = \"Count\"\n",
    "\n",
    "    # Define the plot\n",
    "    plot = figure(plot_height = 600, plot_width = 1000,\n",
    "                    title = \"Histogram of Reviews\",\n",
    "                    x_axis_label = \"Date\",\n",
    "                    y_axis_label = y_axis)    \n",
    "\n",
    "    # Positive plot\n",
    "    plot.quad(bottom = 0, top = x_label,left = \"left\", \n",
    "        right = \"right\", source = src_pos, fill_color = colors[0], \n",
    "        line_color = \"black\", fill_alpha = 1,\n",
    "        hover_fill_alpha = 0.8, hover_fill_color = colors[2])\n",
    "    \n",
    "    # Negative plot\n",
    "    plot.quad(bottom = 0, top = x_label,left = \"left\", \n",
    "        right = \"right\", source = src_neg, fill_color = colors[1], \n",
    "        line_color = \"black\", fill_alpha = 1,\n",
    "        hover_fill_alpha = 0.8, hover_fill_color = colors[2])\n",
    "\n",
    "    plot.xaxis.formatter=DatetimeTickFormatter(\n",
    "            hours=[\"%d %B %Y\"],\n",
    "            days=[\"%d %B %Y\"],\n",
    "            months=[\"%d %B %Y\"],\n",
    "            years=[\"%d %B %Y\"],\n",
    "        )\n",
    "\n",
    "    # Add Hover Tool\n",
    "    hover = HoverTool(tooltips = [('Interval', '@interval'),\n",
    "                              (y_axis, str(\"@\" + x_label)),\n",
    "                              ('Top 5', '@top_n{safe}')])\n",
    "    plot.add_tools(hover)\n",
    "    \n",
    "    # Plot or save\n",
    "    if save_name:\n",
    "        # Save files for offline use\n",
    "        output_file(f'{save_name}.html', mode='inline')\n",
    "        save(plot)\n",
    "    else:\n",
    "        show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_in_notebook=False\n",
    "\n",
    "if show_in_notebook:\n",
    "    # Show plots from Bokeh in notebook\n",
    "    output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviews(df_viz_pos, df_viz_neg, 'timestamp_updated', vectorizer_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviews(df_viz_pos, df_viz_neg, 'timestamp_updated', vectorizer_val, log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plots in html\n",
    "plot_reviews(df_viz_pos, df_viz_neg, 'timestamp_updated', vectorizer_val, save_name='validation_plot')\n",
    "plot_reviews(df_viz_pos, df_viz_neg, 'timestamp_updated', vectorizer_val, log_scale=True, save_name='validation_plot_log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
